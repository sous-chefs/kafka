# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# see kafka.server.KafkaConfig for additional details and defaults

############################# General Configuration #############################

# The id of the broker. This must be set to a unique integer for each broker.
<%= render 'partials/option.erb', variables: {key: 'broker.id', value: node[:kafka][:broker_id]} -%>

# The maximum size of message that the server can receive
<%= render 'partials/option.erb', variables: {key: 'message.max.bytes', value: node[:kafka][:message_max_bytes]} -%>

# The number of network threads that the server uses for handling network requests
<%= render 'partials/option.erb', variables: {key: 'num.network.threads', value: node[:kafka][:num_network_threads]} -%>

# The number of io threads that the server uses for carrying out network requests
<%= render 'partials/option.erb', variables: {key: 'num.io.threads', value: node[:kafka][:num_io_threads]} -%>

# The number of queued requests allowed before blocking the network threads
<%= render 'partials/option.erb', variables: {key: 'queued.max.requests', value: node[:kafka][:queued_max_requests]} -%>

############################# Socket Server Configuration #############################

# The port to listen and accept connections on
<%= render 'partials/option.erb', variables: {key: 'port', value: node[:kafka][:port]} -%>

# Hostname of broker. If this is set, it will only bind to this address. If this is not set,
# it will bind to all interfaces, and publish one to ZK.
<%= render 'partials/option.erb', variables: {key: 'host.name', value: node[:kafka][:host_name]} -%>

# The SO_SNDBUFF buffer of the socket sever sockets
<%= render 'partials/option.erb', variables: {key: 'socket.send.buffer.bytes', value: node[:kafka][:socket][:send_buffer_bytes]} -%>

# The SO_RCVBUFF buffer of the socket sever sockets
<%= render 'partials/option.erb', variables: {key: 'socket.receive.buffer.bytes', value: node[:kafka][:socket][:receive_buffer_bytes]} -%>

# The maximum number of bytes in a socket request
<%= render 'partials/option.erb', variables: {key: 'socket.request.max.bytes', value: node[:kafka][:socket][:request_max_bytes]} -%>

############################# Log Configuration #############################

# The default number of log partitions per topic
<%= render 'partials/option.erb', variables: {key: 'num.partitions', value: node[:kafka][:num_partitions]} -%>

# The directories in which the log data is kept
<%= render 'partials/option.erb', variables: {key: 'log.dirs', value: node[:kafka][:log][:dirs]} -%>

# The maximum size of a single log file
<%= render 'partials/option.erb', variables: {key: 'log.segment.bytes', value: node[:kafka][:log][:segment_bytes]} -%>

# The maximum size of a single log file for some specific topic
<%= render 'partials/hash_option.erb', variables: {key: 'log.segment.bytes.per.topic', value: node[:kafka][:log][:segment_bytes_per_topic]} -%>

# the maximum time before a new log segment is rolled out
<%= render 'partials/option.erb', variables: {key: 'log.roll.hours', value: node[:kafka][:log][:roll_hours]} -%>

# the number of hours before rolling out a new log segment for some specific topic
<%= render 'partials/hash_option.erb', variables: {key: 'log.roll.hours.per.topic', value: node[:kafka][:log][:roll_hours_per_topic]} -%>

# the number of hours to keep a log file before deleting it
<%= render 'partials/option.erb', variables: {key: 'log.retention.hours', value: node[:kafka][:log][:retention_hours]} -%>

# the number of hours to keep a log file before deleting it for some specific topic
<%= render 'partials/hash_option.erb', variables: {key: 'log.retention.hours.per.topic', value: node[:kafka][:log][:retention_hours_per_topic]} -%>

# the maximum size of the log before deleting it
<%= render 'partials/option.erb', variables: {key: 'log.retention.bytes', value: node[:kafka][:log][:retention_bytes]} -%>

# the maximum size of the log for some specific topic before deleting it
<%= render 'partials/hash_option.erb', variables: {key: 'log.retention.bytes.per.topic', value: node[:kafka][:log][:retention_bytes_per_topic]} -%>

# the frequency in minutes that the log cleaner checks whether any log is eligible for deletion
<%= render 'partials/option.erb', variables: {key: 'log.cleanup.interval.mins', value: node[:kafka][:log][:cleanup_interval_mins]} -%>

# the maximum size in bytes of the offset index
<%= render 'partials/option.erb', variables: {key: 'log.index.size.max.bytes', value: node[:kafka][:log][:index_size_max_bytes]} -%>

# the interval with which we add an entry to the offset index
<%= render 'partials/option.erb', variables: {key: 'log.index.interval.bytes', value: node[:kafka][:log][:index_interval_bytes]} -%>

# the number of messages accumulated on a log partition before messages are flushed to disk
<%= render 'partials/option.erb', variables: {key: 'log.flush.interval.messages', value: node[:kafka][:log][:flush_interval_messages]} -%>

# the maximum time in ms that a message in any topic is kept in memory before flushed to disk
<%= render 'partials/option.erb', variables: {key: 'log.flush.interval.ms', value: node[:kafka][:log][:flush_interval_ms]} -%>

# the maximum time in ms that a message in selected topics is kept in memory before flushed to disk, e.g., topic1:3000,topic2:6000
<%= render 'partials/hash_option.erb', variables: {key: 'log.flush.interval.ms.per.topic', value: node[:kafka][:log][:flush_interval_ms_per_topic]} -%>

# the frequency in ms that the log flusher checks whether any log needs to be flushed to disk
<%= render 'partials/option.erb', variables: {key: 'log.flush.scheduler.interval.ms', value: node[:kafka][:log][:flush_scheduler_interval_ms]} -%>

# enable auto creation of topic on the broker
<%= render 'partials/option.erb', variables: {key: 'auto.create.topics.enable', value: node[:kafka][:auto_create_topics]} -%>

############################# Replication Configuration #############################

# the socket timeout for controller-to-broker channels
<%= render 'partials/option.erb', variables: {key: 'controller.socket.timeout.ms', value: node[:kafka][:controller][:socket_timeout_ms]} -%>

# the buffer size for controller-to-broker-channels
<%= render 'partials/option.erb', variables: {key: 'controller.message.queue.size', value: node[:kafka][:controller][:message_queue_size]} -%>

# default replication factor for automatically created topics
<%= render 'partials/option.erb', variables: {key: 'default.replication.factor', value: node[:kafka][:default_replication_factor]} -%>

# if a follower hasn't sent any fetch requests during this time, the leader will remove the follower from isr
<%= render 'partials/option.erb', variables: {key: 'replica.lag.time.max.ms', value: node[:kafka][:replica][:lag_time_max_ms]} -%>

# If the lag in messages between a leader and a follower exceeds this number, the leader will remove the follower from isr
<%= render 'partials/option.erb', variables: {key: 'replica.lag.max.messages', value: node[:kafka][:replica][:lag_max_messages]} -%>

# the socket timeout for network requests
<%= render 'partials/option.erb', variables: {key: 'replica.socket.timeout.ms', value: node[:kafka][:replica][:socket_timeout_ms]} -%>

# the socket receive buffer for network requests
<%= render 'partials/option.erb', variables: {key: 'replica.socket.receive.buffer.bytes', value: node[:kafka][:replica][:socket_receive_buffer_bytes]} -%>

# the number of bytes of messages to attempt to fetch
<%= render 'partials/option.erb', variables: {key: 'replica.fetch.max.bytes', value: node[:kafka][:replica][:fetch_max_bytes]} -%>

# minimum bytes expected for each fetch response. If not enough bytes, wait up to replicaMaxWaitTimeMs
<%= render 'partials/option.erb', variables: {key: 'replica.fetch.min.bytes', value: node[:kafka][:replica][:fetch_min_bytes]} -%>

# max wait time for each fetcher request issued by follower replicas
<%= render 'partials/option.erb', variables: {key: 'replica.fetch.wait.max.ms', value: node[:kafka][:replica][:fetch_wait_max_ms]} -%>

# number of fetcher threads used to replicate messages from a source broker.
# Increasing this value can increase the degree of I/O parallelism in the follower broker.
<%= render 'partials/option.erb', variables: {key: 'num.replica.fetchers', value: node[:kafka][:num_replica_fetchers]} -%>

# the frequency with which the high watermark is saved out to disk
<%= render 'partials/option.erb', variables: {key: 'replica.high.watermark.checkpoint.interval.ms', value: node[:kafka][:replica][:high_watermark_checkpoint_interval_ms]} -%>

# the purge interval (in number of requests) of the fetch request purgatory
<%= render 'partials/option.erb', variables: {key: 'fetch.purgatory.purge.interval.requests', value: node[:kafka][:fetch][:purgatory_purge_interval_requests]} -%>

# the purge interval (in number of requests) of the producer request purgatory
<%= render 'partials/option.erb', variables: {key: 'producer.purgatory.purge.interval.requests', value: node[:kafka][:producer][:purgatory_purge_interval_requests]} -%>

############################# Controlled shutdown configuration #############################

# Controlled shutdown can fail for multiple reasons. This determines the number of retries when such failure happens
<%= render 'partials/option.erb', variables: {key: 'controlled.shutdown.max.retries', value: node[:kafka][:controlled_shutdown][:max_retries]} -%>

# Before each retry, the system needs time to recover from the state that caused the previous failure (Controller
# fail over, replica lag etc). This config determines the amount of time to wait before retrying.
<%= render 'partials/option.erb', variables: {key: 'controlled.shutdown.retry.backoff.ms', value: node[:kafka][:controlled_shutdown][:retry_backoff_ms]} -%>

# enable controlled shutdown of the server
<%= render 'partials/option.erb', variables: {key: 'controlled.shutdown.enable', value: node[:kafka][:controlled_shutdown][:enabled]} -%>

############################# Zookeeper #############################

# Zookeeper connection string (see zookeeper docs for details).
# This is a comma separated host:port pairs, each corresponding to a zk
# server. e.g. "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002".
# You can also append an optional chroot string to the urls to specify the
# root directory for all kafka znodes.
<%= render 'partials/option.erb', variables: {key: 'zookeeper.connect', value: @zookeeper_connect -%>

# the max time that the client waits to establish a connection to zookeeper
<%= render 'partials/option.erb', variables: {key: 'zookeeper.connection.timeout.ms', value: node[:kafka][:zookeeper][:connection_timeout_ms]} -%>

# zookeeper session timeout
<%= render 'partials/option.erb', variables: {key: 'zookeeper.session.timeout.ms', value: node[:kafka][:zookeeper][:session_timeout_ms]} -%>

# how far a ZK follower can be behind a ZK leader
<%= render 'partials/option.erb', variables: {key: 'zookeeper.sync.time.ms', value: node[:kafka][:zookeeper][:sync_time_ms]} -%>
